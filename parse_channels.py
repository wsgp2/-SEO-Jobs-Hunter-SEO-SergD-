"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ SEO –≤–∞–∫–∞–Ω—Å–∏–π –∏–∑ Telegram –∫–∞–Ω–∞–ª–æ–≤ —Å —É—á–µ—Ç–æ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π API
"""

import pandas as pd
from datetime import datetime, timedelta, timezone
from loguru import logger
import os
from seo_channels import SEO_CHANNELS
from telethon import TelegramClient, sync
from telethon.tl.functions.messages import GetHistoryRequest
from telethon.errors import FloodWaitError, SlowModeWaitError, ServerError
from dotenv import load_dotenv
import asyncio
import time
from tqdm import tqdm
import random
from openai import OpenAI
import json
import glob
from stop_words import contains_stop_words
from telegram_notifier import send_vacancy_notification

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Telegram –∫–ª–∏–µ–Ω—Ç–∞
API_ID = os.getenv('API_ID')
API_HASH = os.getenv('API_HASH')
PHONE = "+79222474175"

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞
openai_client = OpenAI(
    api_key=os.getenv('OPENAI_API_KEY')
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ñ–∞–π–ª–æ–≤
DATA_FILE = "data_seohr.xlsx"
SEO_FILE = "seo_vacancies.xlsx"
PROGRESS_FILE = "parsing_progress.json"

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logger.add("parser_log.txt", rotation="1 day")

# –ü–æ–ª—É—á–∞–µ–º –¥–∞—Ç—É –≥–æ–¥ –Ω–∞–∑–∞–¥ —Å —É—á–µ—Ç–æ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∑–æ–Ω—ã
ONE_YEAR_AGO = datetime.now(timezone.utc) - timedelta(days=365)

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π API
MAX_REQUESTS_PER_HOUR = 3000
REQUESTS_INTERVAL = 2  # –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
MAX_BATCH_SIZE = 100   # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –∑–∞ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å
HOURLY_REQUESTS = {}   # —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ –∫–∞–Ω–∞–ª–∞–º

class RateLimiter:
    """–ö–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏ API"""
    def __init__(self):
        self.last_request_time = 0
        self.hourly_requests = {}
    
    async def wait_if_needed(self, channel_username):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –æ–∂–∏–¥–∞–Ω–∏–µ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –∑–∞–ø—Ä–æ—Å–æ–º"""
        current_time = time.time()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —á–∞—Å
        hour_key = f"{channel_username}_{int(current_time / 3600)}"
        self.hourly_requests[hour_key] = self.hourly_requests.get(hour_key, 0) + 1
        
        if self.hourly_requests[hour_key] > MAX_REQUESTS_PER_HOUR:
            wait_time = 3600 - (current_time % 3600)
            logger.warning(f"‚ö†Ô∏è –î–æ—Å—Ç–∏–≥–Ω—É—Ç —á–∞—Å–æ–≤–æ–π –ª–∏–º–∏—Ç –¥–ª—è {channel_username}, –∂–¥–µ–º {wait_time:.0f} —Å–µ–∫—É–Ω–¥")
            await asyncio.sleep(wait_time)
            self.hourly_requests[hour_key] = 0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        time_since_last = current_time - self.last_request_time
        if time_since_last < REQUESTS_INTERVAL:
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—É—é –∑–∞–¥–µ—Ä–∂–∫—É –¥–ª—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
            wait_time = REQUESTS_INTERVAL - time_since_last + random.uniform(0.1, 0.5)
            await asyncio.sleep(wait_time)
        
        self.last_request_time = time.time()

async def get_all_messages(client, channel_username, rate_limiter):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∫–∞–Ω–∞–ª–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –≥–æ–¥"""
    messages = []
    
    try:
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –∫–∞–Ω–∞–ª—É
        channel = await client.get_entity(channel_username)
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
        with tqdm(desc=f"–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ {channel_username}", unit=" —Å–æ–æ–±—â–µ–Ω–∏–π") as pbar:
            offset_id = 0
            total_messages = 0
            retry_count = 0
            
            while True:
                try:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è API
                    await rate_limiter.wait_if_needed(channel_username)
                    
                    history = await client(GetHistoryRequest(
                        peer=channel,
                        limit=MAX_BATCH_SIZE,
                        offset_date=None,
                        offset_id=offset_id,
                        max_id=0,
                        min_id=0,
                        add_offset=0,
                        hash=0
                    ))
                    
                    if not history.messages:
                        break
                        
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞—Ç—É –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
                    last_message = history.messages[-1]
                    message_date = last_message.date.replace(tzinfo=timezone.utc)
                    if message_date < ONE_YEAR_AGO:
                        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –≥–æ–¥
                        for message in history.messages:
                            message_date = message.date.replace(tzinfo=timezone.utc)
                            if message_date >= ONE_YEAR_AGO:
                                messages.append(message)
                        break
                    
                    messages.extend(history.messages)
                    offset_id = history.messages[-1].id
                    total_messages += len(history.messages)
                    pbar.update(len(history.messages))
                    
                    # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –ø–æ–ø—ã—Ç–æ–∫ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
                    retry_count = 0
                    
                except FloodWaitError as e:
                    retry_count += 1
                    wait_time = e.seconds * (2 ** retry_count)  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                    logger.warning(f"‚ö†Ô∏è –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤, –∂–¥–µ–º {wait_time} —Å–µ–∫—É–Ω–¥ (–ø–æ–ø—ã—Ç–∫–∞ {retry_count})")
                    await asyncio.sleep(wait_time)
                    continue
                    
                except SlowModeWaitError as e:
                    logger.warning(f"‚ö†Ô∏è –í–∫–ª—é—á–µ–Ω –º–µ–¥–ª–µ–Ω–Ω—ã–π —Ä–µ–∂–∏–º, –∂–¥–µ–º {e.seconds} —Å–µ–∫—É–Ω–¥")
                    await asyncio.sleep(e.seconds)
                    continue
                    
                except ServerError as e:
                    retry_count += 1
                    wait_time = 5 * (2 ** retry_count)  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}, –∂–¥–µ–º {wait_time} —Å–µ–∫—É–Ω–¥ (–ø–æ–ø—ã—Ç–∫–∞ {retry_count})")
                    if retry_count > 5:  # –ú–∞–∫—Å–∏–º—É–º 5 –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
                        logger.error(f"‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞")
                        break
                    await asyncio.sleep(wait_time)
                    continue
                    
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∫–∞–Ω–∞–ª–∞ {channel_username}: {str(e)}")
    
    return messages

SYSTEM_PROMPT = """–¢—ã HR –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ SEO —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –≤–∞–∫–∞–Ω—Å–∏–µ–π SEO —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞.

–ü—Ä–∞–≤–∏–ª–∞ –æ—Ç–±–æ—Ä–∞ –≤–∞–∫–∞–Ω—Å–∏–π:

1. –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ï –ö–†–ò–¢–ï–†–ò–ò (–≤—Å–µ –¥–æ–ª–∂–Ω—ã –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è):
   - –≠—Ç–æ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤–∞–∫–∞–Ω—Å–∏—è –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ —à—Ç–∞—Ç –∫–æ–º–ø–∞–Ω–∏–∏, —É–¥–∞–ª–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞ –ø–æ–¥—Ö–æ–¥–∏—Ç (–Ω–µ –∞–≥–µ–Ω—Ç—Å—Ç–≤–æ, –Ω–µ —Ñ—Ä–∏–ª–∞–Ω—Å)
   - –í–∞–∫–∞–Ω—Å–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –¥–ª—è SEO-—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞ –∏–ª–∏ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞, –≥–¥–µ SEO - –æ—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å —Ä–∞–±–æ—Ç—ã
   - –†–∞–±–æ—Ç–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –∏ –¥–ª—è —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤
   - –î–æ–ª–∂–Ω–∞ –±—ã—Ç—å —É–∫–∞–∑–∞–Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –∫–æ–º–ø–∞–Ω–∏—è –∏–ª–∏ –ø—Ä–æ–¥—É–∫—Ç

2. –°–¢–û–ü-–§–ê–ö–¢–û–†–´ (–µ—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—å –æ–¥–∏–Ω - –æ—Ç–∫–ª–æ–Ω—è–µ–º):
   - –í–∞–∫–∞–Ω—Å–∏—è –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å adult, gambling, –∫–∞–∑–∏–Ω–æ, –±–µ—Ç—Ç–∏–Ω–≥
   - –†–∞–±–æ—Ç–∞ —Å PBN —Å–µ—Ç–∫–∞–º–∏ –∏–ª–∏ –¥—Ä–æ–ø –¥–æ–º–µ–Ω–∞–º–∏
   - –õ–∏–Ω–∫–±–∏–ª–¥–∏–Ω–≥ –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–∞—è –∑–∞–¥–∞—á–∞
   - –†–∞–±–æ—Ç–∞ —Å –±—É—Ä–∂—É–Ω–µ—Ç–æ–º –∏–ª–∏ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–º–∏ –ø—Ä–æ–µ–∫—Ç–∞–º–∏
   - –ö—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã, —Ç—Ä–µ–π–¥–∏–Ω–≥, web3
   - –í—Ä–µ–º–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞ –∏–ª–∏ –ø—Ä–æ–µ–∫—Ç–Ω–∞—è –∑–∞–Ω—è—Ç–æ—Å—Ç—å
   - –í–∞–∫–∞–Ω—Å–∏—è –∏–∑ –∞–≥–µ–Ω—Ç—Å—Ç–≤–∞ –∏–ª–∏ –¥–ª—è –∞–≥–µ–Ω—Ç—Å—Ç–≤–∞
   - –¢—Ä–µ–±—É–µ—Ç—Å—è –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —è–∑—ã–∫ –≤—ã—à–µ –±–∞–∑–æ–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è

3. –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ü–†–ê–í–ò–õ–ê:
   - –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–∞ –∑–∞—Ä–ø–ª–∞—Ç–∞ - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –Ω–µ –æ—Ç–∫–ª–æ–Ω—è–µ–º
   - –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
   - –ï—Å–ª–∏ –µ—Å—Ç—å —Å–æ–º–Ω–µ–Ω–∏—è - –æ—Ç–∫–ª–æ–Ω—è–µ–º –≤–∞–∫–∞–Ω—Å–∏—é

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—Å—Ç –∏ –≤–µ—Ä–Ω–∏ JSON:
{
    "is_seo": true/false,  # –ü–æ–¥—Ö–æ–¥–∏—Ç –ª–∏ –≤–∞–∫–∞–Ω—Å–∏—è –ø–æ–¥ –Ω–∞—à–∏ –∫—Ä–∏—Ç–µ—Ä–∏–∏
    "reason": "string",    # –ü—Ä–∏—á–∏–Ω–∞ —Ä–µ—à–µ–Ω–∏—è, –æ—Å–æ–±–µ–Ω–Ω–æ –≤–∞–∂–Ω–æ –µ—Å–ª–∏ –æ—Ç–∫–ª–æ–Ω—è–µ–º
    "contacts": "string",  # –ù–∞–π–¥–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ç–∞–∫—Ç—ã (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    "salary": "string"     # –ù–∞–π–¥–µ–Ω–Ω–∞—è –∑–∞—Ä–ø–ª–∞—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
}"""

def analyze_message(text):
    """–ê–Ω–∞–ª–∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è SEO –∏ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤"""
    try:
        messages = [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": text}
        ]
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤, —Ç–∞–∫ –∫–∞–∫ OpenAI Python SDK –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –≤—ã–∑–æ–≤—ã
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=0,
            response_format={"type": "json_object"}
        )
        
        result = json.loads(response.choices[0].message.content)
        logger.debug(f"‚ú® –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞: {result}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à—É—é –∑–∞–¥–µ—Ä–∂–∫—É –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        time.sleep(0.5)
        
        return result
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –¥–µ–ª–∞–µ–º –±–æ–ª–µ–µ –¥–ª–∏—Ç–µ–ª—å–Ω—É—é –ø–∞—É–∑—É
        time.sleep(2)
        return {
            "is_seo": False,
            "reason": f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}",
            "contacts": None,
            "salary": None
        }

def is_seo_vacancy(text: str) -> tuple[bool, str]:
    """
    –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ SEO –≤–∞–∫–∞–Ω—Å–∏—é
    
    Returns:
        tuple: (–ø—Ä–æ—à–µ–ª –ø—Ä–æ–≤–µ—Ä–∫—É, –ø—Ä–∏—á–∏–Ω–∞ –æ—Ç–∫–∞–∑–∞ –µ—Å–ª–∏ –Ω–µ –ø—Ä–æ—à–µ–ª)
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ None –∏ –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç
    if text is None or not str(text).strip():
        return False, "–ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç"
    
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ —Å—Ç—Ä–æ–∫–µ –∏ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    text = str(text).lower()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ SEO –≤ —Ç–µ–∫—Å—Ç–µ
    if not any(keyword in text for keyword in ['seo', '—Å–µ–æ']):
        return False, "–ù–µ—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏—è SEO"
        
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
    if contains_stop_words(text):
        return False, "–°–æ–¥–µ—Ä–∂–∏—Ç —Å—Ç–æ–ø-—Å–ª–æ–≤–∞"
        
    return True, ""

async def process_messages(messages):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–∏—Å–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π"""
    all_messages = []
    seo_messages = []
    
    for message in messages:
        try:
            channel = message['channel']
            text = message['text']
            date = message['date']
            views = message.get('views', 0)
            forwards = message.get('forwards', 0)
            message_link = message.get('message_link', '')
            
            message_data = {
                'channel': channel,
                'text': text,
                'date': date,
                'views': views,
                'forwards': forwards,
                'message_link': message_link,
                'contains_seo_vacancy': False,
                'reason': "",
                'contacts': None,
                'salary': None
            }
            
            # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
            passed_initial_check, reject_reason = is_seo_vacancy(text)
            
            if not passed_initial_check:
                message_data['reason'] = reject_reason
                all_messages.append(message_data)
                continue
            
            # –ï—Å–ª–∏ –ø—Ä–æ—à–ª–∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ –∞–Ω–∞–ª–∏–∑ –≤ ChatGPT
            analysis = await analyze_message(text)
            message_data.update({
                'contains_seo_vacancy': analysis['is_seo'],
                'reason': analysis['reason'],
                'contacts': analysis['contacts'],
                'salary': analysis['salary']
            })
            
            if analysis['is_seo']:
                seo_messages.append(message_data)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º SEO –≤–∞–∫–∞–Ω—Å–∏–∏ —Å—Ä–∞–∑—É –≤ –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª
                df_seo = pd.DataFrame(seo_messages)
                df_seo.to_excel(SEO_FILE, index=False)
                logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(seo_messages)} SEO –≤–∞–∫–∞–Ω—Å–∏–π")
            
            all_messages.append(message_data)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
            continue
    
    return all_messages, seo_messages

async def save_to_excel(messages):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ Excel"""
    try:
        # –°–æ–∑–¥–∞–µ–º DataFrame
        df = pd.DataFrame(messages)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
        df = df.sort_values('date', ascending=False)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â—É—é –≤–µ—Ä—Å–∏—é
        df.to_excel('seo_vacancies.xlsx', index=False)
        
        # –°–æ–∑–¥–∞–µ–º –±—ç–∫–∞–ø —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π
        timestamp = datetime.now().strftime('%Y%m%d_%H%M')
        df.to_excel(f'seo_vacancies_{timestamp}.xlsx', index=False)
        
        logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ Excel")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ –Ω–æ–≤—ã—Ö –≤–∞–∫–∞–Ω—Å–∏—è—Ö
        for _, row in df.iterrows():
            if row['contains_seo_vacancy']:
                await send_vacancy_notification(row.to_dict())
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ Excel: {e}")
        raise

def load_progress():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
    if os.path.exists(PROGRESS_FILE):
        with open(PROGRESS_FILE, 'r') as f:
            return json.load(f)
    return {"processed_channels": [], "last_message_ids": {}}

def save_progress(progress):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
    with open(PROGRESS_FILE, 'w') as f:
        json.dump(progress, f)

def load_existing_data():
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
    all_messages = []
    seo_messages = []
    
    if os.path.exists(DATA_FILE):
        try:
            df = pd.read_excel(DATA_FILE)
            all_messages = df.to_dict('records')
        except Exception as e:
            logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {DATA_FILE}: {e}")
    
    if os.path.exists(SEO_FILE):
        try:
            df = pd.read_excel(SEO_FILE)
            seo_messages = df.to_dict('records')
        except Exception as e:
            logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {SEO_FILE}: {e}")
    
    return all_messages, seo_messages

def clean_temp_files():
    """–£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    for pattern in ["data_seohr_*_temp.xlsx", "seo_vacancies_*_temp.xlsx"]:
        for file in glob.glob(pattern):
            try:
                os.remove(file)
                logger.debug(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {file}")
            except Exception as e:
                logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ {file}: {e}")

async def parse_all_channels(client):
    """–ü–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö –∫–∞–Ω–∞–ª–æ–≤ –∏–∑ —Å–ø–∏—Å–∫–∞"""
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
    progress = load_progress()
    all_messages, seo_messages = load_existing_data()
    rate_limiter = RateLimiter()
    
    for channel in SEO_CHANNELS:
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∫–∞–Ω–∞–ª—ã
        if channel['username'] in progress['processed_channels']:
            logger.info(f"‚è© –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∫–∞–Ω–∞–ª: {channel['name']}")
            continue
            
        logger.info(f"üîÑ –ü–∞—Ä—Å–∏–º –∫–∞–Ω–∞–ª: {channel['name']}")
        
        try:
            messages = await get_all_messages(client, channel['username'], rate_limiter)
            
            for msg in messages:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–ª–∏ –ª–∏ –º—ã —É–∂–µ —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ
                if str(msg.id) in progress.get('last_message_ids', {}).get(channel['username'], []):
                    continue
                    
                text = msg.message
                message_link = f"https://t.me/{channel['username']}/{msg.id}"
                message_date = msg.date.replace(tzinfo=None)
                
                message_data = {
                    'channel_name': channel['name'],
                    'channel_username': channel['username'],
                    'message_id': msg.id,
                    'date': message_date,
                    'text': text,
                    'views': getattr(msg, 'views', 0),
                    'forwards': getattr(msg, 'forwards', 0),
                    'message_link': message_link
                }
                
                # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
                passed_initial_check, reject_reason = is_seo_vacancy(text)
                
                if not passed_initial_check:
                    message_data['contains_seo_vacancy'] = False
                    message_data['reason'] = reject_reason
                    all_messages.append(message_data)
                    continue
                
                # –ï—Å–ª–∏ –ø—Ä–æ—à–ª–∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ –∞–Ω–∞–ª–∏–∑ –≤ ChatGPT
                analysis = await analyze_message(text)
                message_data.update({
                    'contains_seo_vacancy': analysis['is_seo'],
                    'reason': analysis['reason'],
                    'contacts': analysis['contacts'],
                    'salary': analysis['salary']
                })
                
                if analysis['is_seo']:
                    seo_messages.append(message_data)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º SEO –≤–∞–∫–∞–Ω—Å–∏–∏ —Å—Ä–∞–∑—É –≤ –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª
                    df_seo = pd.DataFrame(seo_messages)
                    df_seo.to_excel(SEO_FILE, index=False)
                    logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(seo_messages)} SEO –≤–∞–∫–∞–Ω—Å–∏–π")
                
                all_messages.append(message_data)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª
                if len(all_messages) % 10 == 0:
                    df = pd.DataFrame(all_messages)
                    df.to_excel(DATA_FILE, index=False)
                    logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(all_messages)} —Å–æ–æ–±—â–µ–Ω–∏–π")
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                if channel['username'] not in progress['last_message_ids']:
                    progress['last_message_ids'][channel['username']] = []
                progress['last_message_ids'][channel['username']].append(str(msg.id))
                save_progress(progress)
            
            # –ü–æ–º–µ—á–∞–µ–º –∫–∞–Ω–∞–ª –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π
            progress['processed_channels'].append(channel['username'])
            save_progress(progress)
            
            logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∫–∞–Ω–∞–ª–∞ {channel['name']}")
            
        except Exception as e:
            logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –∫–∞–Ω–∞–ª–∞ {channel['name']}: {e}")
            # –ü—Ä–∏ –æ—à–∏–±–∫–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∫–∞–Ω–∞–ª–∞
            save_progress(progress)
            continue
    
    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    df = pd.DataFrame(all_messages)
    df.to_excel(DATA_FILE, index=False)
    logger.info(f"üíæ –í—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {DATA_FILE}")
    
    df_seo = pd.DataFrame(seo_messages)
    df_seo.to_excel(SEO_FILE, index=False)
    logger.info(f"üíæ SEO –≤–∞–∫–∞–Ω—Å–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {SEO_FILE}")
    
    # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    clean_temp_files()

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    max_retries = 5
    retry_count = 0
    
    while retry_count < max_retries:
        try:
            client = TelegramClient('seo_parser_session', API_ID, API_HASH)
            await client.start(PHONE)
            
            await parse_all_channels(client)
            break
            
        except Exception as e:
            retry_count += 1
            wait_time = 5 * (2 ** retry_count)
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            logger.info(f"üîÑ –ü–æ–ø—ã—Ç–∫–∞ {retry_count} –∏–∑ {max_retries}, –æ–∂–∏–¥–∞–Ω–∏–µ {wait_time} —Å–µ–∫—É–Ω–¥")
            await asyncio.sleep(wait_time)
            
        finally:
            try:
                await client.disconnect()
            except:
                pass
    
    if retry_count >= max_retries:
        logger.error("‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫")

if __name__ == '__main__':
    asyncio.run(main())
